{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CndVY51ENbZi"
   },
   "source": [
    "# K Nearest Neighbour Search \n",
    "\n",
    "A k-nearest neighbor (kNN) search finds the k nearest vectors to a query vector, as measured by a similarity metric. \n",
    "\n",
    "We will use the kNN algorithm to find some nearest neighbors and then compute the recall of the neighborhood we found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ev7Y79FYJS1P",
    "outputId": "bd214285-1555-4135-b725-197313ad1b58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\conne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bA_aH-lSCQl"
   },
   "source": [
    "We will be using Amazon Reviews Dataset. This dataset consists of a few million Amazon customer reviews (input text) and star ratings (output labels). Additional information found here: https://s3.amazonaws.com/amazon-reviews-pds/readme.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eFztkx7E14Lt"
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xp1DHNsu3J-h",
    "outputId": "ce0f0737-ab17-4bcf-8e42-ef0210911182"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the shape of the dataframe\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "qpXur067l2q2",
    "outputId": "29839a59-2f90-48ed-bb7e-17e079ee6186"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "7                     0                       0      5  1336003200   \n",
       "8                     1                       1      5  1322006400   \n",
       "9                     0                       0      5  1351209600   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                          Good Quality Dog Food   \n",
       "1                              Not as Advertised   \n",
       "2                          \"Delight\" says it all   \n",
       "3                                 Cough Medicine   \n",
       "4                                    Great taffy   \n",
       "5                                     Nice Taffy   \n",
       "6  Great!  Just as good as the expensive brands!   \n",
       "7                         Wonderful, tasty taffy   \n",
       "8                                     Yay Barley   \n",
       "9                               Healthy Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  \n",
       "5  I got a wild hair for taffy and ordered this f...  \n",
       "6  This saltwater taffy had great flavors and was...  \n",
       "7  This taffy is so good.  It is very soft and ch...  \n",
       "8  Right now I'm mostly just sprouting this so my...  \n",
       "9  This is a very healthy dog food. Good for thei...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvinrJ45QZO0"
   },
   "source": [
    "Text preprocessing \n",
    "\n",
    "We will be removing stop-words, any punctuations or limited set of special characters like , or . or # etc. Then, we go on to snowball stemming the word and convert it to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vJLdTUv0qs64"
   },
   "outputs": [],
   "source": [
    "# Set of stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# Initialising the snowball stemmer\n",
    "sno = nltk.stem.SnowballStemmer('english') \n",
    "\n",
    "# Function to clean the word of any html-tags\n",
    "def cleanhtml(sentence): \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "\n",
    "# Function to clean the word of any punctuation or special characters\n",
    "def cleanpunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "\n",
    "# Store words from +ve reviews \n",
    "all_positive_words=[]\n",
    "\n",
    "# Store words from -ve reviews\n",
    "all_negative_words=[] \n",
    "s=''\n",
    "\n",
    "final_string=[]\n",
    "all_positive_words=[] \n",
    "all_negative_words=[] \n",
    "s=''\n",
    "for sent in data['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "\n",
    "    # Remove HTMl tags\n",
    "    sent=cleanhtml(sent) \n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAa6zXeVRAYA"
   },
   "source": [
    "Generate bag of words vector matrix for reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZfLc1SSix7x3"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer() \n",
    "final_bow_count = count_vect.fit_transform(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H5o7zLU13bEv"
   },
   "outputs": [],
   "source": [
    "final_bow_np = StandardScaler(with_mean=False).fit_transform(final_bow_count )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8eTAhjNRJvS"
   },
   "source": [
    "Split the data into Train and Test into a 9:1 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ytcJIeZW3yDC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 16482)\n",
      "(2000, 16482)\n"
     ]
    }
   ],
   "source": [
    "X = final_bow_np\n",
    "X_train =  final_bow_np[:math.ceil(len(data)*.9)] \n",
    "X_test = final_bow_np[math.ceil(len(data)*.9):]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the 50 nearest neighbors for each sample in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sr02yfD-lNsd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.17 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "k = 50\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='cosine').fit(X_train)\n",
    "distances, neighbors = nbrs.kneighbors(X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2waknjX0HPh",
    "outputId": "911ac5d9-5c7f-42e0-eef5-e7d734f5ab93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.18464162e-01, 7.16116166e-01, 7.55184269e-01, ...,\n",
       "        9.39110042e-01, 9.39593503e-01, 9.39595312e-01],\n",
       "       [6.84371145e-01, 7.00441545e-01, 7.02512885e-01, ...,\n",
       "        8.69142303e-01, 8.70446927e-01, 8.70674543e-01],\n",
       "       [5.34895648e-01, 6.37843018e-01, 6.56247624e-01, ...,\n",
       "        9.12725473e-01, 9.13171758e-01, 9.13337868e-01],\n",
       "       ...,\n",
       "       [0.00000000e+00, 6.27357430e-01, 6.80607607e-01, ...,\n",
       "        9.17175649e-01, 9.18609906e-01, 9.18658569e-01],\n",
       "       [0.00000000e+00, 4.72554556e-01, 6.08074531e-01, ...,\n",
       "        9.28125513e-01, 9.28183424e-01, 9.28417540e-01],\n",
       "       [2.22044605e-16, 5.65968666e-01, 5.89778151e-01, ...,\n",
       "        8.88874262e-01, 8.88950398e-01, 8.89400426e-01]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P3Ae_dJfIH0I",
    "outputId": "256b95ee-d82c-4312-8f94-012df803d38c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12186, 13757, 13091, ..., 13728, 12408,  7513],\n",
       "       [ 9565,  7384, 10521, ...,  9948, 12740, 10799],\n",
       "       [17992, 17338, 17998, ..., 15123,   352,   807],\n",
       "       ...,\n",
       "       [11088, 12352, 11107, ...,  1771,  4423,  3060],\n",
       "       [11089, 17989,  7498, ...,  9398,  7994,  1629],\n",
       "       [11090, 11543, 11687, ...,  1527, 15503,  7154]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the average recall of the found neighbors. For each sample, the recall is computed as the number of found neighbors divided by the number of neighbors to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z8W3eb7KL9Pz"
   },
   "outputs": [],
   "source": [
    "def recall(pred, gt):\n",
    "    \"\"\"Compute the recall of the pred neighborhood vs. the gt neighborhood\"\"\"\n",
    "    if pred.shape[0] == 1:\n",
    "        return len(set(pred).intersection(set(gt)))/len(gt)\n",
    "    assert pred.shape[0] == gt.shape[0]\n",
    "    return np.array([len(set(pred[i]).intersection(set(gt[i])))/len(gt[i]) for i in range(len(pred))]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029100000000000003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall for a random assignment of neighbors\n",
    "recall(np.random.randint(len(neighbors), size=(len(neighbors), k)), neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9399999999999995"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall if the last 3 neighbors were missed for each sample\n",
    "recall(neighbors[:, range(k-3)], neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss-me5avMKqf",
    "outputId": "977a5e13-5f7a-4b95-933d-e7ee27ca6f73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall if you found all the correct neighbors\n",
    "recall(neighbors, neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Mz8QtMWbEOC"
   },
   "source": [
    "# References\n",
    "\n",
    "1. https://scikit-learn.org/stable/modules/neighbors.html\n",
    "3. https://medium.com/analytics-vidhya/k-nearest-neighbor-algorithm-with-amazon-food-reviews-analysis-14d83a4cadea \n",
    "4. https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEtAwM8KS27Z"
   },
   "source": [
    "# Task\n",
    "\n",
    "1. Execute Approximate Nearest Neighbor search using TWO of the tools of your choice from the ANN benchmarks. https://ann-benchmarks.com/. Please visit http://github.com/erikbern/ann-benchmarks/ to get an overview of evaluated algorithms and their performance.\n",
    "\n",
    "2. Train your ANN models for k=50 using the Train-Test split above and tune their parameters to achieve a recall of at least 80%.\n",
    "\n",
    "3. For each method, display the recall as well as the overall time (training and search) for the search process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faiss\n",
    "import faiss\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# References\n",
    "# https://github.com/facebookresearch/faiss/wiki/Getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train and test data\n",
    "X_train_norm = normalize(X_train, norm=\"l1\")\n",
    "X_test_norm = normalize(X_test, norm=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "18000\n",
      "[[13757 12186 13091  5310 13578  5313 14393  5966 14213 17578 10482 10225\n",
      "  12873  6236 16031 12417  2343  1587 13656 12408 12228  9939  2869 13660\n",
      "   7903  9790   580  9668  6015 11861 10494 10083  3625  2291 16002 13728\n",
      "   7740  6083 16135 15911  8600  9309  7513   575 11097  3040  4805  2147\n",
      "  14448  6813]\n",
      " [10521  9565  7384 10334 17524  7267 10634 12218 10371   662  6521 17909\n",
      "  10186 13162  4195 17942  9967  7726  4038 12173  3084    58  8397  9106\n",
      "   9950  3808   199 11913  2768  3461 11858  3355  3083 10706 16314 10981\n",
      "   7402 16306  6424 16901   351  4383  4591 16766 10383 16563  7108 15127\n",
      "   9105  8396]\n",
      " [12887 13544 17338 17992 17998  7475 15544 16415 14519 15758 15003 11448\n",
      "   2766  6112  5332 17703   482  1590 13525 12847  2078  4590 14969 16185\n",
      "  10818  5966 17973 13501 17091 14300  1891 17048 17263  5737  4066 17984\n",
      "   5675  5617  3033  3175  7507 16551   705 11241 13743  3806  2581 14380\n",
      "   5566 14866]\n",
      " [ 5229 15997  4465 11343 16241 15699 12377 13657 17413 11276 13278  7702\n",
      "  14543  3403  9074  8365 17470  6499  4881  6157  1115 16307 16331  7536\n",
      "   6825  1500   273  5332  1543  3508  2885  8283 17077 15519  7022 11860\n",
      "   7012  1767 17706 16370 16356  1713  3629  6305   510  9280  8571  3711\n",
      "   7736 15639]\n",
      " [17964 11686 11097  3282   632 17979 10818  8470  9179 13609  4333 17183\n",
      "   7437  2567  1755   694 14092  5299  2378 17961 17941 17973  5285  6083\n",
      "  17402 17068  5468  2585    60 11233 17092  2506 17197  1773 10274 12084\n",
      "  15897  3256 16151  4051 12431  3427  9878  4473 16830 10820 17943 10720\n",
      "   5633 14681]]\n",
      "[[11086 11079 17128 11085 12058  8871 13546 11171  6476 11400 10434   757\n",
      "  11971  3576 16123  1718  6409   102 16338  8109 11106   433  1741 15558\n",
      "   2405  1226  9886 13774 17979  6774  6431 11078  1715  3301   517 12040\n",
      "  14543  5518  7180  3729   558  2279 11103  8844  7877  3716 15134 16713\n",
      "  11097   464]\n",
      " [11087  8402  9111 17701 15076 16184  9891  8110 15821  4897 17969  7496\n",
      "  17832 12788  6055   997  3474  5479 11705 13218  6945  9488 12847  5133\n",
      "    151  4274  3161  8009  7215 13413  4144 15967  9533  1809 14839  6568\n",
      "   3286  4430  7580 10654 11718  1393 13766  3379  3471  6257 17943  4628\n",
      "  15861 16904]\n",
      " [11088 11107 12352  8559  9268  1765  6101  1842  1736  9536 11111 10408\n",
      "   1744  4530  1608  3531   527 14331   912  6545  1663 12291   639  1760\n",
      "  11228  5718 16169  3060  5306 14345  1714 10037  9251  8542 16745  1771\n",
      "   1681 12936  1801  4423   698 16942  9568   460   319 10947   264 17068\n",
      "   1611  1612]\n",
      " [11089 17989  7899  7498 11095   434   590  6224   435 15108 11078 10709\n",
      "   1715 10321 11079 10163 16359 12646 10234 11465 17457 10055  1470 15006\n",
      "  12808 10451  8019  1693  4027  4029   751 13823 12847   427  3049  5409\n",
      "    591  4656  5613  7927    25  3662  7085   516   583  2881  1629 16364\n",
      "    633  9218]\n",
      " [11090 11543 11687  1224  5871 15967 16865 17978 12459  1660 16240  9399\n",
      "   8690   558 12309  3872 15503 15537 10998  2822  8981 14554  1395 10445\n",
      "    106 10156   438  3577 12229  1790 12959   955  2014  9714 15846  6771\n",
      "   8561  9270 12996 16020  1718  3489  7131 17306   667  3253  3586  3462\n",
      "  17601 16848]]\n",
      "CPU times: total: 7min 39s\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set type to float 32 numpy array\n",
    "xb = np.array(X_train_norm.toarray()).astype(np.float32)\n",
    "xq = np.array(X_test_norm.toarray()).astype(np.float32)\n",
    "d = X_train_norm.shape[1]\n",
    "\n",
    "# Add to faiss index\n",
    "index = faiss.IndexFlatIP(d)   \n",
    "print(index.is_trained)\n",
    "index.add(xb)                  \n",
    "print(index.ntotal)\n",
    "\n",
    "# Full nearest neighbors search + print neighbors for first/last 5 queries\n",
    "k = 50 \n",
    "D, I = index.search(xq, k)\n",
    "print(I[:5])\n",
    "print(I[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7863199999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Faiss Recall\n",
    "recall(I, neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NNDescent\n",
    "from pynndescent import NNDescent\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Reference\n",
    "# https://github.com/lmcinnes/pynndescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14min 46s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Run NNDescent with reduced-dimensional data\n",
    "index = NNDescent(X_train, metric=\"cosine\", n_neighbors=100)\n",
    "I = index.query(X_test, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8976200000000001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NNDescent Recall\n",
    "recall(I[0], neighbors)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
